{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout, Lambda, Conv2D, MaxPooling2D, merge, Reshape, regularizers, Activation\n",
    "from keras.models import Model, model_from_json, load_model, Sequential\n",
    "from keras import callbacks\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras import regularizers\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import backend as K\n",
    "from keras.regularizers import l2\n",
    "from utils import load_data\n",
    "from numpy import newaxis\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "#####  rotation = 20, width shift = 0.1, height shit = 0.1, zoom range = 0.2, hotizontal flip\n",
    "##### among the operations, flip horizontally will improve the performance significanly \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation to prevent overfitting and generate more training data\n",
    "def data_augmentation(batch_size, image_source, classes):\n",
    "    # tested different ways of data augmentation, flip horizontally will improve the performance significantly\n",
    "    train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20.0,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    rescale=1.0/255,\n",
    "    horizontal_flip=True)\n",
    "    \n",
    "    # only rescale for testing data\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "    \n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "    image_source+\"/training\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\")\n",
    "    \n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "    image_source+\"/validation\",\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\")\n",
    "    \n",
    "    return train_generator, validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Architecture\n",
    "##### VGG16 was selected as the base model. The last COV block feature output was passed into outer product operation with itself to create more features and then the results were passed into the activation layer. \n",
    "##### The outer product operation will create more feature combinations, so as to classify more classes. As the problem is a fine grained classification problem, having more features will help recognize the inter-class and intra-class difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions for bilinear product\n",
    "def outer_product(x):\n",
    "    return K.batch_dot(x[0], x[1], axes = [1, 1]) / x[0].get_shape().as_list()[1]\n",
    "def signed_sqrt(x):\n",
    "    return K.sign(x)*K.sqrt(K.abs(x) + 1e-9)\n",
    "def l2_normalize(x, axis = -1):\n",
    "    return K.l2_normalize(x, axis=axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture\n",
    "def VGG16_outerproduct(classes, dropoutrate, model_name):\n",
    "    K.clear_session()\n",
    "    \n",
    "    # VGG16 as base for extract features\n",
    "    base_model = VGG16(input_shape = (224, 224, 3), include_top = False, weights = \"imagenet\")\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    # Get output from VGG16 end layer features\n",
    "    feature_model_1 = base_model\n",
    "    x1 = feature_model_1.layers[17].output\n",
    "    x1_shape = feature_model_1.layers[17].output_shape\n",
    "    \n",
    "    feature_model_2 = base_model\n",
    "    x2 = feature_model_2.layers[17].output\n",
    "    x2_shape = feature_model_2.layers[17].output_shape\n",
    "    \n",
    "    # reshape to (batch_size, total_pixels, filter_size) for outer product\n",
    "    x1 = Reshape(\n",
    "        [x1_shape[1]*x1_shape[2], x1_shape[-1]])(x1)\n",
    "    x2 = Reshape(\n",
    "        [x2_shape[1]*x2_shape[2], x2_shape[-1]])(x2)\n",
    "    \n",
    "    # Outer product of VGG16 features\n",
    "    x = Lambda(outer_product)([x1, x2])\n",
    "    x = Reshape([x1_shape[-1]*x2_shape[-1]])(x)\n",
    "    x = Lambda(signed_sqrt)(x)\n",
    "    x = Lambda(l2_normalize)(x)\n",
    "    \n",
    "    # Final dense layer\n",
    "    x = Dense(units=len(classes), kernel_initializer=\"glorot_uniform\",\n",
    "              kernel_regularizer=l2(1e-08),\n",
    "             bias_initializer=\"glorot_uniform\")(x)\n",
    "    \n",
    "    prediction = Activation(activation=\"softmax\")(x)\n",
    "    \n",
    "    model = Model(inputs = base_model.input, outputs=prediction)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Tarining Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Fine tune the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune the last year for initial training\n",
    "def fine_tune_last_layer(model,train_generator, validation_generator,batch_size, Epochs, model_name, lr, decay, paitence, optimizer_name = \"adam\"):\n",
    "    \n",
    "    if optimizer_name == \"adam\":\n",
    "        opt_mizer = Adam(lr = lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        opt_mizer = RMSprop(lr = lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt_mizer = SGD(lr = lr, decay = decay, momentum=0.9, nesterov= None)\n",
    "    else:\n",
    "        raise RuntimeError(\"Optimizer not found.\")\n",
    "         \n",
    "    model.compile(optimizer = opt_mizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    # early_stop, reduce_lr and checkpoint\n",
    "    early_stop = EarlyStopping('val_acc', patience=paitence)\n",
    "    reduce_lr = ReduceLROnPlateau('val_acc', factor=0.1, patience=int(paitence/4), verbose=1)\n",
    "    checpoint_dir = os.path.join(model_name + '.{epoch:02d}-{val_acc:.2f}.h5')\n",
    "    model_checkpoint = ModelCheckpoint(checpoint_dir, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "    callbacks = [model_checkpoint, early_stop, reduce_lr]\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = nb_train_samples // batch_size, \n",
    "        epochs = Epochs, \n",
    "        validation_data = validation_generator, \n",
    "        validation_steps = nb_val_samples // batch_size,\n",
    "        callbacks = callbacks)\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"final_transfer_learning_\" + model_name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"final_transfer_learning_\" + model_name + \".h5\")\n",
    "    print(\"Saved model.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Fine tune all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tune all layers\n",
    "def fine_tune_all_layers(model, train_generator, validation_generator, Epochs, model_name, lr, paitence, optimizer_name = \"adam\"):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    if optimizer_name == \"adam\":\n",
    "        opt_mizer = Adam(lr = lr)\n",
    "    elif optimizer_name == \"rmsprop\":\n",
    "        opt_mizer = RMSprop(lr = lr)\n",
    "    elif optimizer_name == \"sgd\":\n",
    "        opt_mizer = SGD(lr = lr, momentum=0.9, nesterov= None)\n",
    "    else:\n",
    "        raise RuntimeError(\"Optimizer not found.\")\n",
    "        \n",
    "    model.compile(optimizer = opt_mizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    \n",
    "    early_stop = EarlyStopping('val_acc', patience=paitence)\n",
    "    reduce_lr = ReduceLROnPlateau('val_acc', factor=0.1, patience=int(paitence/4),verbose=1)\n",
    "    checpoint_dir = os.path.join(\"all\"+model_name + '.{epoch:02d}-{val_acc:.2f}.h5')\n",
    "    model_checkpoint = ModelCheckpoint(checpoint_dir, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "    callbacks = [model_checkpoint, early_stop, reduce_lr]\n",
    "    \n",
    "    hist = model.fit_generator(\n",
    "        train_generator, \n",
    "        steps_per_epoch = nb_train_samples // batch_size, \n",
    "        epochs = Epochs, \n",
    "        validation_data = validation_generator, \n",
    "        validation_steps = nb_val_samples // batch_size,\n",
    "        callbacks = callbacks)\n",
    "    \n",
    "    model_json = model.to_json()\n",
    "    with open(\"final_all_transfer_learning_\" + model_name + \".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(\"final_all_transfer_learning_\" + model_name + \".h5\")\n",
    "    print(\"Saved model.\") \n",
    "    \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune The Last Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Set Hyperparameters for initial training, \"SGD\" was selected as the optimizer with learning rate = 0.1 and decay = 1e-8. Batchsize = 64, Epochs = 500.\n",
    "##### 2. Load training data and validation data using real time augmentation, training size = 6509, validation size = 1635.\n",
    "##### 3. Initialize VGG16_outerproduct model and only train the last layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for initial training\n",
    "lr = 0.1\n",
    "epochs = 500\n",
    "dropout_rate  = 0.5\n",
    "batch_size = 64\n",
    "model_name = \"VGG19\"\n",
    "paitence = 10\n",
    "optimizer_name = \"sgd\"\n",
    "decay = 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = load_data(\"devkit/cars_meta.mat\", \"class\", \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6509 images belonging to 196 classes.\n",
      "Found 1635 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# get trainning and validation data\n",
    "train_generator, validation_generator = data_augmentation(batch_size=batch_size, image_source=\"data/\",classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = 6509\n",
    "nb_val_samples = 1635  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True    # to allow gpu growth\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "model = VGG16_outerproduct(classes=classes,dropoutrate=dropout_rate,model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\User\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/500\n",
      "101/101 [==============================] - 86s 852ms/step - loss: 5.3007 - acc: 0.0053 - val_loss: 5.2724 - val_acc: 0.0088\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.00875, saving model to VGG19.01-0.01.h5\n",
      "Epoch 2/500\n",
      "101/101 [==============================] - 86s 851ms/step - loss: 5.2746 - acc: 0.0084 - val_loss: 5.2594 - val_acc: 0.0083\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.00875\n",
      "Epoch 3/500\n",
      "101/101 [==============================] - 81s 803ms/step - loss: 5.2633 - acc: 0.0082 - val_loss: 5.2484 - val_acc: 0.0089\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.00875 to 0.00891, saving model to VGG19.03-0.01.h5\n",
      "Epoch 4/500\n",
      "101/101 [==============================] - 81s 804ms/step - loss: 5.2545 - acc: 0.0076 - val_loss: 5.2432 - val_acc: 0.0089\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.00891\n",
      "Epoch 5/500\n",
      "101/101 [==============================] - 80s 791ms/step - loss: 5.2452 - acc: 0.0091 - val_loss: 5.2343 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.00891\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n",
      "Epoch 6/500\n",
      "101/101 [==============================] - 80s 792ms/step - loss: 5.2311 - acc: 0.0084 - val_loss: 5.2313 - val_acc: 0.0115\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.00891 to 0.01146, saving model to VGG19.06-0.01.h5\n",
      "Epoch 7/500\n",
      "101/101 [==============================] - 81s 805ms/step - loss: 5.2294 - acc: 0.0084 - val_loss: 5.2307 - val_acc: 0.0095\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.01146\n",
      "Epoch 8/500\n",
      "101/101 [==============================] - 81s 799ms/step - loss: 5.2282 - acc: 0.0084 - val_loss: 5.2327 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.01146\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "Epoch 9/500\n",
      "101/101 [==============================] - 81s 799ms/step - loss: 5.2269 - acc: 0.0081 - val_loss: 5.2281 - val_acc: 0.0095\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.01146\n",
      "Epoch 10/500\n",
      "101/101 [==============================] - 80s 793ms/step - loss: 5.2263 - acc: 0.0084 - val_loss: 5.2313 - val_acc: 0.0076\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.01146\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 9.999999310821295e-05.\n",
      "Epoch 11/500\n",
      "101/101 [==============================] - 81s 806ms/step - loss: 5.2268 - acc: 0.0084 - val_loss: 5.2313 - val_acc: 0.0102\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.01146\n",
      "Epoch 12/500\n",
      "101/101 [==============================] - 87s 858ms/step - loss: 5.2275 - acc: 0.0076 - val_loss: 5.2314 - val_acc: 0.0070\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.01146\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999019782991e-06.\n",
      "Epoch 13/500\n",
      "101/101 [==============================] - 80s 794ms/step - loss: 5.2261 - acc: 0.0085 - val_loss: 5.2282 - val_acc: 0.0095\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.01146\n",
      "Epoch 14/500\n",
      "101/101 [==============================] - 81s 800ms/step - loss: 5.2263 - acc: 0.0082 - val_loss: 5.2328 - val_acc: 0.0057\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.01146\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-07.\n",
      "Epoch 15/500\n",
      "101/101 [==============================] - 82s 811ms/step - loss: 5.2255 - acc: 0.0087 - val_loss: 5.2287 - val_acc: 0.0108\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.01146\n",
      "Epoch 16/500\n",
      "101/101 [==============================] - 82s 811ms/step - loss: 5.2266 - acc: 0.0078 - val_loss: 5.2335 - val_acc: 0.0083\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.01146\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 9.99999883788405e-08.\n",
      "Saved model.\n"
     ]
    }
   ],
   "source": [
    "# fine tunning last layer\n",
    "fine_tune_last_layer(model=model, train_generator=train_generator, validation_generator=validation_generator, batch_size=batch_size,Epochs=epochs,lr=lr,decay =decay,model_name=model_name,paitence=paitence, optimizer_name=optimizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tune All Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Set Hyperparameters for training, \"ADAM\" was selected as the optimizer with learning rate = 0.0001 and no decay. Batchsize = 64, Epochs = 500.\n",
    "##### 2. The best model results achieved 99% training accuracy, 89.2% validation accuracy and 87.8 testing accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "#load model from pre-trained\n",
    "#load json and create model\n",
    "json_file = open(\"final_transfer_learning_VGG16.json\", 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "model.load_weights(\"final_transfer_learning_VGG16.h5\")\n",
    "print('Loaded model from disk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters for fine tune all layers\n",
    "lr = 0.0001\n",
    "epochs = 500\n",
    "dropout_rate  = 0.5\n",
    "batch_size = 64\n",
    "model_name = \"VGG16\"\n",
    "paitence = 20\n",
    "optimizer_name = \"adam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "101/101 [==============================] - 91s 903ms/step - loss: 5.0437 - acc: 0.0438 - val_loss: 4.7548 - val_acc: 0.1229\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.12285, saving model to allVGG19.01-0.12.h5\n",
      "Epoch 2/500\n",
      "101/101 [==============================] - 87s 862ms/step - loss: 4.4408 - acc: 0.1767 - val_loss: 4.0935 - val_acc: 0.2896\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.12285 to 0.28962, saving model to allVGG19.02-0.29.h5\n",
      "Epoch 3/500\n",
      "101/101 [==============================] - 88s 868ms/step - loss: 3.8115 - acc: 0.3093 - val_loss: 3.5068 - val_acc: 0.4157\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.28962 to 0.41566, saving model to allVGG19.03-0.42.h5\n",
      "Epoch 4/500\n",
      "101/101 [==============================] - 90s 887ms/step - loss: 3.2490 - acc: 0.4416 - val_loss: 2.9803 - val_acc: 0.4825\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.41566 to 0.48250, saving model to allVGG19.04-0.48.h5\n",
      "Epoch 5/500\n",
      "101/101 [==============================] - 87s 864ms/step - loss: 2.7354 - acc: 0.5332 - val_loss: 2.5638 - val_acc: 0.5703\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.48250 to 0.57034, saving model to allVGG19.05-0.57.h5\n",
      "Epoch 6/500\n",
      "101/101 [==============================] - 86s 853ms/step - loss: 2.2926 - acc: 0.6302 - val_loss: 2.2030 - val_acc: 0.6085\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.57034 to 0.60853, saving model to allVGG19.06-0.61.h5\n",
      "Epoch 7/500\n",
      "101/101 [==============================] - 86s 855ms/step - loss: 1.9114 - acc: 0.6905 - val_loss: 1.8114 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00007: val_acc improved from 0.60853 to 0.69637, saving model to allVGG19.07-0.70.h5\n",
      "Epoch 8/500\n",
      "101/101 [==============================] - 88s 873ms/step - loss: 1.5704 - acc: 0.7457 - val_loss: 1.5765 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.69637 to 0.72183, saving model to allVGG19.08-0.72.h5\n",
      "Epoch 9/500\n",
      "101/101 [==============================] - 88s 871ms/step - loss: 1.2910 - acc: 0.7995 - val_loss: 1.3299 - val_acc: 0.7575\n",
      "\n",
      "Epoch 00009: val_acc improved from 0.72183 to 0.75748, saving model to allVGG19.09-0.76.h5\n",
      "Epoch 10/500\n",
      "101/101 [==============================] - 86s 856ms/step - loss: 1.0574 - acc: 0.8352 - val_loss: 1.1283 - val_acc: 0.8008\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.75748 to 0.80076, saving model to allVGG19.10-0.80.h5\n",
      "Epoch 11/500\n",
      "101/101 [==============================] - 86s 850ms/step - loss: 0.8676 - acc: 0.8636 - val_loss: 0.9982 - val_acc: 0.8052\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.80076 to 0.80522, saving model to allVGG19.11-0.81.h5\n",
      "Epoch 12/500\n",
      "101/101 [==============================] - 86s 853ms/step - loss: 0.7079 - acc: 0.8907 - val_loss: 0.9150 - val_acc: 0.8113\n",
      "\n",
      "Epoch 00012: val_acc improved from 0.80522 to 0.81125, saving model to allVGG19.12-0.81.h5\n",
      "Epoch 13/500\n",
      "101/101 [==============================] - 86s 847ms/step - loss: 0.6036 - acc: 0.9037 - val_loss: 0.8124 - val_acc: 0.8256\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.81125 to 0.82559, saving model to allVGG19.13-0.83.h5\n",
      "Epoch 14/500\n",
      "101/101 [==============================] - 87s 858ms/step - loss: 0.4912 - acc: 0.9182 - val_loss: 0.7423 - val_acc: 0.8243\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.82559\n",
      "Epoch 15/500\n",
      "101/101 [==============================] - 86s 847ms/step - loss: 0.4292 - acc: 0.9284 - val_loss: 0.7026 - val_acc: 0.8300\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.82559 to 0.83004, saving model to allVGG19.15-0.83.h5\n",
      "Epoch 16/500\n",
      "101/101 [==============================] - 86s 852ms/step - loss: 0.3690 - acc: 0.9378 - val_loss: 0.6661 - val_acc: 0.8402\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.83004 to 0.84023, saving model to allVGG19.16-0.84.h5\n",
      "Epoch 17/500\n",
      "101/101 [==============================] - 86s 853ms/step - loss: 0.3095 - acc: 0.9453 - val_loss: 0.6566 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.84023\n",
      "Epoch 18/500\n",
      "101/101 [==============================] - 87s 862ms/step - loss: 0.2767 - acc: 0.9538 - val_loss: 0.5948 - val_acc: 0.8485\n",
      "\n",
      "Epoch 00018: val_acc improved from 0.84023 to 0.84850, saving model to allVGG19.18-0.85.h5\n",
      "Epoch 19/500\n",
      "101/101 [==============================] - 88s 871ms/step - loss: 0.2390 - acc: 0.9557 - val_loss: 0.5587 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.84850 to 0.84914, saving model to allVGG19.19-0.85.h5\n",
      "Epoch 20/500\n",
      "101/101 [==============================] - 85s 841ms/step - loss: 0.2172 - acc: 0.9575 - val_loss: 0.5991 - val_acc: 0.8421\n",
      "\n",
      "Epoch 00020: val_acc did not improve from 0.84914\n",
      "Epoch 21/500\n",
      "101/101 [==============================] - 84s 834ms/step - loss: 0.2001 - acc: 0.9621 - val_loss: 0.6427 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.84914\n",
      "Epoch 22/500\n",
      "101/101 [==============================] - 85s 839ms/step - loss: 0.1966 - acc: 0.9627 - val_loss: 0.5500 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.84914 to 0.85232, saving model to allVGG19.22-0.85.h5\n",
      "Epoch 23/500\n",
      "101/101 [==============================] - 84s 834ms/step - loss: 0.1624 - acc: 0.9694 - val_loss: 0.5982 - val_acc: 0.8415\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.85232\n",
      "Epoch 24/500\n",
      "101/101 [==============================] - 85s 841ms/step - loss: 0.1688 - acc: 0.9662 - val_loss: 0.5186 - val_acc: 0.8523\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.85232\n",
      "Epoch 25/500\n",
      "101/101 [==============================] - 85s 844ms/step - loss: 0.1427 - acc: 0.9724 - val_loss: 0.5844 - val_acc: 0.8332\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.85232\n",
      "Epoch 26/500\n",
      "101/101 [==============================] - 85s 837ms/step - loss: 0.1304 - acc: 0.9756 - val_loss: 0.5127 - val_acc: 0.8612\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.85232 to 0.86123, saving model to allVGG19.26-0.86.h5\n",
      "Epoch 27/500\n",
      "101/101 [==============================] - 86s 854ms/step - loss: 0.1179 - acc: 0.9781 - val_loss: 0.5915 - val_acc: 0.8390\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.86123\n",
      "Epoch 28/500\n",
      "101/101 [==============================] - 90s 895ms/step - loss: 0.1240 - acc: 0.9729 - val_loss: 0.5557 - val_acc: 0.8415\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.86123\n",
      "Epoch 29/500\n",
      "101/101 [==============================] - 84s 834ms/step - loss: 0.1127 - acc: 0.9766 - val_loss: 0.5373 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.86123\n",
      "Epoch 30/500\n",
      "101/101 [==============================] - 85s 840ms/step - loss: 0.1046 - acc: 0.9790 - val_loss: 0.5585 - val_acc: 0.8339\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.86123\n",
      "Epoch 31/500\n",
      "101/101 [==============================] - 85s 842ms/step - loss: 0.1012 - acc: 0.9776 - val_loss: 0.6164 - val_acc: 0.8377\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.86123\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "Epoch 32/500\n",
      "101/101 [==============================] - 86s 847ms/step - loss: 0.0690 - acc: 0.9872 - val_loss: 0.4697 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00032: val_acc improved from 0.86123 to 0.86505, saving model to allVGG19.32-0.87.h5\n",
      "Epoch 33/500\n",
      "101/101 [==============================] - 87s 857ms/step - loss: 0.0499 - acc: 0.9929 - val_loss: 0.5078 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.86505\n",
      "Epoch 34/500\n",
      "101/101 [==============================] - 85s 839ms/step - loss: 0.0461 - acc: 0.9945 - val_loss: 0.4758 - val_acc: 0.8670\n",
      "\n",
      "Epoch 00034: val_acc improved from 0.86505 to 0.86696, saving model to allVGG19.34-0.87.h5\n",
      "Epoch 35/500\n",
      "101/101 [==============================] - 86s 852ms/step - loss: 0.0439 - acc: 0.9944 - val_loss: 0.4912 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.86696\n",
      "Epoch 36/500\n",
      "101/101 [==============================] - 87s 860ms/step - loss: 0.0406 - acc: 0.9954 - val_loss: 0.4994 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.86696\n",
      "Epoch 37/500\n",
      "101/101 [==============================] - 87s 866ms/step - loss: 0.0407 - acc: 0.9949 - val_loss: 0.4682 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00037: val_acc improved from 0.86696 to 0.87333, saving model to allVGG19.37-0.87.h5\n",
      "Epoch 38/500\n",
      "101/101 [==============================] - 88s 869ms/step - loss: 0.0377 - acc: 0.9951 - val_loss: 0.4886 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.87333\n",
      "Epoch 39/500\n",
      "101/101 [==============================] - 87s 860ms/step - loss: 0.0365 - acc: 0.9955 - val_loss: 0.4827 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.87333\n",
      "Epoch 40/500\n",
      "101/101 [==============================] - 86s 854ms/step - loss: 0.0359 - acc: 0.9971 - val_loss: 0.4969 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.87333\n",
      "Epoch 41/500\n",
      "101/101 [==============================] - 90s 892ms/step - loss: 0.0343 - acc: 0.9959 - val_loss: 0.4641 - val_acc: 0.8746\n",
      "\n",
      "Epoch 00041: val_acc improved from 0.87333 to 0.87460, saving model to allVGG19.41-0.87.h5\n",
      "Epoch 42/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0353 - acc: 0.9947 - val_loss: 0.5001 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00042: val_acc did not improve from 0.87460\n",
      "Epoch 43/500\n",
      "101/101 [==============================] - 86s 847ms/step - loss: 0.0319 - acc: 0.9966 - val_loss: 0.4915 - val_acc: 0.8657\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.87460\n",
      "Epoch 44/500\n",
      "101/101 [==============================] - 86s 856ms/step - loss: 0.0334 - acc: 0.9958 - val_loss: 0.4875 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.87460\n",
      "Epoch 45/500\n",
      "101/101 [==============================] - 85s 843ms/step - loss: 0.0302 - acc: 0.9977 - val_loss: 0.4649 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.87460\n",
      "Epoch 46/500\n",
      "101/101 [==============================] - 85s 846ms/step - loss: 0.0300 - acc: 0.9968 - val_loss: 0.5066 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.87460\n",
      "\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "Epoch 47/500\n",
      "101/101 [==============================] - 84s 831ms/step - loss: 0.0302 - acc: 0.9961 - val_loss: 0.4539 - val_acc: 0.8797\n",
      "\n",
      "Epoch 00047: val_acc improved from 0.87460 to 0.87969, saving model to allVGG19.47-0.88.h5\n",
      "Epoch 48/500\n",
      "101/101 [==============================] - 84s 827ms/step - loss: 0.0297 - acc: 0.9974 - val_loss: 0.4955 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.87969\n",
      "Epoch 49/500\n",
      "101/101 [==============================] - 86s 856ms/step - loss: 0.0296 - acc: 0.9969 - val_loss: 0.4893 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.87969\n",
      "Epoch 50/500\n",
      "101/101 [==============================] - 86s 854ms/step - loss: 0.0293 - acc: 0.9966 - val_loss: 0.5070 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.87969\n",
      "Epoch 51/500\n",
      "101/101 [==============================] - 85s 838ms/step - loss: 0.0277 - acc: 0.9981 - val_loss: 0.4764 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.87969\n",
      "Epoch 52/500\n",
      "101/101 [==============================] - 84s 828ms/step - loss: 0.0273 - acc: 0.9975 - val_loss: 0.4625 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.87969\n",
      "\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "Epoch 53/500\n",
      "101/101 [==============================] - 85s 842ms/step - loss: 0.0290 - acc: 0.9968 - val_loss: 0.5153 - val_acc: 0.8619\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.87969\n",
      "Epoch 54/500\n",
      "101/101 [==============================] - 90s 892ms/step - loss: 0.0293 - acc: 0.9968 - val_loss: 0.4681 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.87969\n",
      "Epoch 55/500\n",
      "101/101 [==============================] - 86s 855ms/step - loss: 0.0271 - acc: 0.9975 - val_loss: 0.4992 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.87969\n",
      "Epoch 56/500\n",
      "101/101 [==============================] - 86s 856ms/step - loss: 0.0273 - acc: 0.9980 - val_loss: 0.4733 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.87969\n",
      "Epoch 57/500\n",
      "101/101 [==============================] - 86s 851ms/step - loss: 0.0285 - acc: 0.9972 - val_loss: 0.5087 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.87969\n",
      "\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "Epoch 58/500\n",
      "101/101 [==============================] - 84s 833ms/step - loss: 0.0280 - acc: 0.9978 - val_loss: 0.4777 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.87969\n",
      "Epoch 59/500\n",
      "101/101 [==============================] - 84s 831ms/step - loss: 0.0276 - acc: 0.9978 - val_loss: 0.4652 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.87969\n",
      "Epoch 60/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0271 - acc: 0.9985 - val_loss: 0.5031 - val_acc: 0.8663\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.87969\n",
      "Epoch 61/500\n",
      "101/101 [==============================] - 84s 827ms/step - loss: 0.0285 - acc: 0.9972 - val_loss: 0.4738 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.87969\n",
      "Epoch 62/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0271 - acc: 0.9980 - val_loss: 0.4764 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.87969\n",
      "\n",
      "Epoch 00062: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "Epoch 63/500\n",
      "101/101 [==============================] - 87s 863ms/step - loss: 0.0276 - acc: 0.9981 - val_loss: 0.4909 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.87969\n",
      "Epoch 64/500\n",
      "101/101 [==============================] - 85s 840ms/step - loss: 0.0286 - acc: 0.9972 - val_loss: 0.4869 - val_acc: 0.8694\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.87969\n",
      "Epoch 65/500\n",
      "101/101 [==============================] - 83s 820ms/step - loss: 0.0280 - acc: 0.9981 - val_loss: 0.4731 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.87969\n",
      "Epoch 66/500\n",
      "101/101 [==============================] - 84s 828ms/step - loss: 0.0260 - acc: 0.9980 - val_loss: 0.5111 - val_acc: 0.8638\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.87969\n",
      "Epoch 67/500\n",
      "101/101 [==============================] - 84s 835ms/step - loss: 0.0283 - acc: 0.9972 - val_loss: 0.4523 - val_acc: 0.8803\n",
      "\n",
      "Epoch 00067: val_acc improved from 0.87969 to 0.88033, saving model to allVGG19.67-0.88.h5\n",
      "Epoch 68/500\n",
      "101/101 [==============================] - 82s 816ms/step - loss: 0.0281 - acc: 0.9968 - val_loss: 0.4972 - val_acc: 0.8631\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.88033\n",
      "Epoch 69/500\n",
      "101/101 [==============================] - 84s 836ms/step - loss: 0.0280 - acc: 0.9972 - val_loss: 0.4562 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.88033\n",
      "Epoch 70/500\n",
      "101/101 [==============================] - 84s 828ms/step - loss: 0.0284 - acc: 0.9969 - val_loss: 0.5030 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.88033\n",
      "Epoch 71/500\n",
      "101/101 [==============================] - 84s 829ms/step - loss: 0.0260 - acc: 0.9986 - val_loss: 0.4994 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.88033\n",
      "Epoch 72/500\n",
      "101/101 [==============================] - 83s 823ms/step - loss: 0.0279 - acc: 0.9971 - val_loss: 0.4607 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.88033\n",
      "\n",
      "Epoch 00072: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "Epoch 73/500\n",
      "101/101 [==============================] - 84s 834ms/step - loss: 0.0289 - acc: 0.9978 - val_loss: 0.5026 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.88033\n",
      "Epoch 74/500\n",
      "101/101 [==============================] - 87s 862ms/step - loss: 0.0270 - acc: 0.9977 - val_loss: 0.4927 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.88033\n",
      "Epoch 75/500\n",
      "101/101 [==============================] - 84s 833ms/step - loss: 0.0286 - acc: 0.9981 - val_loss: 0.4762 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.88033\n",
      "Epoch 76/500\n",
      "101/101 [==============================] - 83s 824ms/step - loss: 0.0273 - acc: 0.9975 - val_loss: 0.4534 - val_acc: 0.8822\n",
      "\n",
      "Epoch 00076: val_acc improved from 0.88033 to 0.88224, saving model to allVGG19.76-0.88.h5\n",
      "Epoch 77/500\n",
      "101/101 [==============================] - 84s 828ms/step - loss: 0.0267 - acc: 0.9980 - val_loss: 0.5202 - val_acc: 0.8600\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.88224\n",
      "Epoch 78/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0275 - acc: 0.9976 - val_loss: 0.4765 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.88224\n",
      "Epoch 79/500\n",
      "101/101 [==============================] - 83s 825ms/step - loss: 0.0276 - acc: 0.9978 - val_loss: 0.4974 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.88224\n",
      "Epoch 80/500\n",
      "101/101 [==============================] - 84s 834ms/step - loss: 0.0258 - acc: 0.9986 - val_loss: 0.4691 - val_acc: 0.8714\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.88224\n",
      "Epoch 81/500\n",
      "101/101 [==============================] - 83s 825ms/step - loss: 0.0283 - acc: 0.9980 - val_loss: 0.4684 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.88224\n",
      "\n",
      "Epoch 00081: ReduceLROnPlateau reducing learning rate to 9.99999943962493e-12.\n",
      "Epoch 82/500\n",
      "101/101 [==============================] - 84s 835ms/step - loss: 0.0285 - acc: 0.9971 - val_loss: 0.5425 - val_acc: 0.8625\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.88224\n",
      "Epoch 83/500\n",
      "101/101 [==============================] - 87s 857ms/step - loss: 0.0276 - acc: 0.9978 - val_loss: 0.4463 - val_acc: 0.8791\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.88224\n",
      "Epoch 84/500\n",
      "101/101 [==============================] - 84s 829ms/step - loss: 0.0279 - acc: 0.9975 - val_loss: 0.5190 - val_acc: 0.8593\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.88224\n",
      "Epoch 85/500\n",
      "101/101 [==============================] - 83s 825ms/step - loss: 0.0285 - acc: 0.9975 - val_loss: 0.4377 - val_acc: 0.8816\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.88224\n",
      "Epoch 86/500\n",
      "101/101 [==============================] - 84s 828ms/step - loss: 0.0287 - acc: 0.9972 - val_loss: 0.5012 - val_acc: 0.8651\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.88224\n",
      "\n",
      "Epoch 00086: ReduceLROnPlateau reducing learning rate to 9.999999092680235e-13.\n",
      "Epoch 87/500\n",
      "101/101 [==============================] - 84s 829ms/step - loss: 0.0280 - acc: 0.9975 - val_loss: 0.4896 - val_acc: 0.8689\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.88224\n",
      "Epoch 88/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0273 - acc: 0.9976 - val_loss: 0.4734 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.88224\n",
      "Epoch 89/500\n",
      "101/101 [==============================] - 85s 842ms/step - loss: 0.0284 - acc: 0.9971 - val_loss: 0.4879 - val_acc: 0.8695\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.88224\n",
      "Epoch 90/500\n",
      "101/101 [==============================] - 85s 842ms/step - loss: 0.0280 - acc: 0.9980 - val_loss: 0.4783 - val_acc: 0.8712\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.88224\n",
      "Epoch 91/500\n",
      "101/101 [==============================] - 85s 841ms/step - loss: 0.0274 - acc: 0.9974 - val_loss: 0.4899 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.88224\n",
      "\n",
      "Epoch 00091: ReduceLROnPlateau reducing learning rate to 9.9999988758398e-14.\n",
      "Epoch 92/500\n",
      "101/101 [==============================] - 86s 848ms/step - loss: 0.0271 - acc: 0.9974 - val_loss: 0.4809 - val_acc: 0.8740\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.88224\n",
      "Epoch 93/500\n",
      "101/101 [==============================] - 88s 872ms/step - loss: 0.0285 - acc: 0.9974 - val_loss: 0.4874 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.88224\n",
      "Epoch 94/500\n",
      "101/101 [==============================] - 84s 835ms/step - loss: 0.0286 - acc: 0.9973 - val_loss: 0.4887 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.88224\n",
      "Epoch 95/500\n",
      "101/101 [==============================] - 84s 830ms/step - loss: 0.0258 - acc: 0.9985 - val_loss: 0.4684 - val_acc: 0.8733\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.88224\n",
      "Epoch 96/500\n",
      "101/101 [==============================] - 2754s 27s/step - loss: 0.0294 - acc: 0.9967 - val_loss: 0.4910 - val_acc: 0.8682\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.88224\n",
      "\n",
      "Epoch 00096: ReduceLROnPlateau reducing learning rate to 9.999999146890344e-15.\n",
      "Saved model.\n"
     ]
    }
   ],
   "source": [
    "history = fine_tune_all_layers(model = model, train_generator = train_generator, validation_generator = validation_generator, Epochs = epochs, model_name = model_name, lr = lr, paitence = paitence, optimizer_name = optimizer_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "##### 1. Bilinear CNN Models for Fine-grained Visual Recognitionhttp://vis-www.cs.umass.edu/bcnn/docs/bcnn_iccv15.pdf\n",
    "##### 2. https://github.com/tkhs3/BCNN_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
